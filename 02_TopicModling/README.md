# Topic Modeling
* 
---
# Algorithms
## LSA (Latent Semantic Analysis, 잠재 의미 분석)
* 정의: Truncated SVD로 차원 축소를 통해 단어의 잠재적 의미를 도출하는 방법이다.
* 배경: BoW, Tf-idf와 같이 단어의 빈도수를 기반으로 등장한 개념은 단어의 의미 정보를 고려하기 어려워 이를 개선하고자 등장하였다.
* 장점: 문서의 유사도 계산 시 좋은 성능을 보인다.
* 단점
    1. 새로운 정보에 대한 업데이트가 어렵다. (이미 계산된 LSA에 새로운 데이터를 추가할 때 처음부터 계산해야 한다.)
    2. 차원 축소를 통해 주요 단어를 추출하지만, 여전히 단어의 순서는 고려하지 못 하기 때문에 문맥을 이해하는 데에는 무리가 있다.
* 단점 보완 방향: Word2Vec, 인공신경망 기반 방법론 등 새로운 벡터화 방법 사용
## LDA (Latent Dirichlet Allocation, 잠재 디리클레 할당)
* 정의: 문서 내에서 등장한 단어가 어떤 토픽에 해당하는 지 알아보기 위하여 아래 두 가지를 고려하여 확률 구하는 방법이다.
    1. 전체 문서에서 동일한 단어가 어떤 토픽에 포함되어 있는가?
    2. 단어가 속한 문서 내에서 어떤 토픽이 많은 비중을 차지하는가?
* LSA와의 차이점
    * LSA: 빈도수 기반 단어 벡터의 차원을 축소하여 근접 단어들을 토픽으로 묶는 것
    * LDA: 단어가 특정 토픽 그룹에 존재할 확률과 문서 내에 토픽 그룹이 포함된 비율을 결합하여, 어떤 토픽 그룹에 할당할 지 추정하는 것
* 단점: LSA와 마찬가지로 여전히 단어의 '빈도수' 기반으로 고려하므로 단어의 순서는 고려하지 못한다.

---
# References
`내용을 공부하면서 참고한 문서를 모두 포함하고 있습니다.`
1. [딥 러닝을 이용한 자연어 처리 입문 / 19-01 잠재 의미 분석 (Latent Semantic Analysis)](https://wikidocs.net/24949)
2. [딥 러닝을 이용한 자연어 처리 입문 / 19-02 잠재 디리클레 할당 (Latent Dirichlet Allocation)](https://wikidocs.net/30708)